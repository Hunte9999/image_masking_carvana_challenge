{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import scipy.misc as scipy\n",
    "from tensorboardX import SummaryWriter\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from kaggle_data.downloader import KaggleDataDownloader\n",
    "\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(image, mean=0, std=1.):\n",
    "    \"\"\"\n",
    "    Transforms an image to a tensor\n",
    "    Args:\n",
    "        image (np.ndarray): A RGB array image\n",
    "        mean: The mean of the image values\n",
    "        std: The standard deviation of the image values\n",
    "\n",
    "    Returns:\n",
    "        tensor: A Pytorch tensor\n",
    "    \"\"\"\n",
    "    image = image.astype(np.float32)\n",
    "    image = (image - mean) / std\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    tensor = torch.from_numpy(image)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def mask_to_tensor(mask, threshold):\n",
    "    \"\"\"\n",
    "    Transforms a mask to a tensor\n",
    "    Args:\n",
    "        mask (np.ndarray): A greyscale mask array\n",
    "        threshold: The threshold used to consider the mask present or not\n",
    "\n",
    "    Returns:\n",
    "        tensor: A Pytorch tensor\n",
    "    \"\"\"\n",
    "    mask = mask\n",
    "    mask = (mask > threshold).astype(np.float32)\n",
    "    tensor = torch.from_numpy(mask).type(torch.FloatTensor)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py#L66\n",
    "class TrainImageDataset(data.Dataset):\n",
    "    def __init__(self, X_data, y_data=None, input_img_resize=(128, 128), output_img_resize=(128, 128),\n",
    "                 X_transform=None, y_transform=None, threshold=0.5):\n",
    "        \"\"\"\n",
    "            A dataset loader taking images paths as argument and return\n",
    "            as them as tensors from getitem()\n",
    "\n",
    "            Args:\n",
    "                threshold (float): The threshold used to consider the mask present or not\n",
    "                X_data (list): List of paths to the training images\n",
    "                y_data (list, optional): List of paths to the target images\n",
    "                input_img_resize (tuple): Tuple containing the new size of the input images\n",
    "                output_img_resize (tuple): Tuple containing the new size of the output images\n",
    "                X_transform (callable, optional): A function/transform that takes in 2 numpy arrays.\n",
    "                    Assumes X_data and y_data are not None.\n",
    "                    (train_img, mask_img) and returns a transformed version with the same signature\n",
    "                y_transform (callable, optional): A function/transform that takes in 2 numpy arrays.\n",
    "                    Assumes X_data and y_data are not None.\n",
    "                    (train_img, mask_img) and returns a transformed version with the same signature\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.X_train = X_data\n",
    "        self.y_train_masks = y_data\n",
    "        self.input_img_resize = input_img_resize\n",
    "        self.output_img_resize = output_img_resize\n",
    "        self.y_transform = y_transform\n",
    "        self.X_transform = X_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                index (int): Index\n",
    "            Returns:\n",
    "                tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        img = Image.open(self.X_train[index])\n",
    "        img = img.resize(self.input_img_resize, Image.ANTIALIAS)\n",
    "        img = np.asarray(img.convert(\"RGB\"), dtype=np.float32)\n",
    "\n",
    "        # Pillow reads gifs\n",
    "        mask = Image.open(self.y_train_masks[index])\n",
    "        mask = mask.resize(self.output_img_resize, Image.ANTIALIAS)\n",
    "        mask = np.asarray(mask.convert(\"L\"), dtype=np.float32)  # GrayScale\n",
    "\n",
    "        if self.X_transform:\n",
    "            img, mask = self.X_transform(img, mask)\n",
    "\n",
    "        if self.y_transform:\n",
    "            img, mask = self.y_transform(img, mask)\n",
    "\n",
    "        img = transformer.image_to_tensor(img)\n",
    "        mask = transformer.mask_to_tensor(mask, self.threshold)\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.X_train) == len(self.y_train_masks)\n",
    "        return len(self.X_train)\n",
    "\n",
    "\n",
    "class TestImageDataset(data.Dataset):\n",
    "    def __init__(self, X_data, img_resize=(128, 128)):\n",
    "        \"\"\"\n",
    "            A dataset loader taking images paths as argument and return\n",
    "            as them as tensors from getitem()\n",
    "            Args:\n",
    "                X_data (list): List of paths to the training images\n",
    "                img_resize (tuple): Tuple containing the new size of the images\n",
    "        \"\"\"\n",
    "        self.img_resize = img_resize\n",
    "        self.X_train = X_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        img_path = self.X_train[index]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize(self.img_resize, Image.ANTIALIAS)\n",
    "        img = np.asarray(img.convert(\"RGB\"), dtype=np.float32)\n",
    "\n",
    "        img = transformer.image_to_tensor(img)\n",
    "        return img, img_path.split(\"/\")[-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_time(show_func_name=True):\n",
    "    \"\"\"\n",
    "        Decorator to calculate the total time of a func\n",
    "\n",
    "    Args:\n",
    "        show_func_name (bool): Whether to show the function name or not\n",
    "    \"\"\"\n",
    "\n",
    "    def wrapper(func):\n",
    "        def st_func(*args, **keyArgs):\n",
    "            t1 = time.time()\n",
    "            r = func(*args, **keyArgs)\n",
    "            t2 = time.time()\n",
    "            if show_func_name:\n",
    "                print(\"Function=%s, Time elapsed = %ds\" % (func.__name__, t2 - t1))\n",
    "            else:\n",
    "                print(\"Time elapsed = %ds\" % (t2 - t1))\n",
    "            return r\n",
    "\n",
    "        return st_func\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def clear_logs_folder():\n",
    "    \"\"\"\n",
    "        Clear the output directories such\n",
    "        as output/ and logs/\n",
    "\n",
    "    \"\"\"\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    folder = os.path.join(script_dir, '../logs/')\n",
    "    for the_file in folder:\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "def get_model_timestamp():\n",
    "    \"\"\"\n",
    "        Returns a timestamp string formatted for\n",
    "        file names\n",
    "    Returns:\n",
    "        str: Timestamp string\n",
    "    \"\"\"\n",
    "    ts = time.time()\n",
    "    return datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%Hh%M')\n",
    "\n",
    "\n",
    "class DatasetFetcher:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            A tool used to automatically download, check, split and get\n",
    "            relevant information on the dataset\n",
    "        \"\"\"\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.train_masks_data = None\n",
    "        self.train_files = None\n",
    "        self.test_files = None\n",
    "        self.train_masks_files = None\n",
    "        self.train_ids = None\n",
    "        self.masks_ids = None\n",
    "        self.test_ids = None\n",
    "\n",
    "    def download_dataset(self, hq_files=False):\n",
    "        \"\"\"\n",
    "        Downloads the dataset and return the input paths\n",
    "        Args:\n",
    "            hq_files (bool): Whether to download the hq files or not\n",
    "\n",
    "        Returns:\n",
    "            list: [train_data, test_data, metadata_csv, train_masks_csv, train_masks_data]\n",
    "\n",
    "        \"\"\"\n",
    "        competition_name = \"carvana-image-masking-challenge\"\n",
    "\n",
    "        destination_path = '../input/'\n",
    "        prefix = \"\"\n",
    "        if hq_files:\n",
    "            prefix = \"_hq\"\n",
    "        files = [\"train\" + prefix + \".zip\", \"test\" + prefix + \".zip\", \"metadata.csv.zip\",\n",
    "                 \"train_masks.csv.zip\", \"train_masks.zip\"]\n",
    "        datasets_path = [destination_path + \"train\" + prefix, destination_path + \"test\" + prefix,\n",
    "                         destination_path + \"metadata.csv\", destination_path + \"train_masks.csv\",\n",
    "                         destination_path + \"train_masks\"]\n",
    "        is_datasets_present = True\n",
    "\n",
    "        # If the folders already exists then the files may already be extracted\n",
    "        # This is a bit hacky but it's sufficient for our needs\n",
    "        for dir_path in datasets_path:\n",
    "            if not os.path.exists(dir_path):\n",
    "                is_datasets_present = False\n",
    "\n",
    "        if not is_datasets_present:\n",
    "            # Put your Kaggle user name and password in a $KAGGLE_USER and $KAGGLE_PASSWD env vars respectively\n",
    "            downloader = KaggleDataDownloader('frostics', os.getenv(\"KAGGLE_PASSWD\"), competition_name)\n",
    "\n",
    "            for file in files:\n",
    "                output_path = downloader.download_dataset(file, destination_path)\n",
    "                downloader.decompress(output_path, destination_path)\n",
    "                os.remove(output_path)\n",
    "        else:\n",
    "            print(\"All datasets are present.\")\n",
    "\n",
    "        self.train_data = datasets_path[0]\n",
    "        self.test_data = datasets_path[1]\n",
    "        self.train_masks_data = datasets_path[4]\n",
    "        self.train_files = sorted(os.listdir(self.train_data))\n",
    "        self.test_files = sorted(os.listdir(self.test_data))\n",
    "        self.train_masks_files = sorted(os.listdir(self.train_masks_data))\n",
    "        self.train_ids = list(set(t.split(\"_\")[0] for t in self.train_files))\n",
    "        self.masks_ids = list(set(t.split(\"_\")[0] for t in self.train_masks_files))\n",
    "        self.test_ids = list(set(t.split(\"_\")[0] for t in self.test_files))\n",
    "        return datasets_path\n",
    "\n",
    "    def get_car_image_files(self, car_image_id, test_file=False, get_mask=False):\n",
    "        if get_mask:\n",
    "            if car_image_id in self.masks_ids:\n",
    "                return [self.train_masks_data + \"/\" + s for s in self.train_masks_files if car_image_id in s]\n",
    "            else:\n",
    "                raise Exception(\"No mask with this ID found\")\n",
    "        elif test_file:\n",
    "            if car_image_id in self.test_ids:\n",
    "                return [self.test_data + \"/\" + s for s in self.test_files if car_image_id in s]\n",
    "        else:\n",
    "            if car_image_id in self.train_ids:\n",
    "                return [self.train_data + \"/\" + s for s in self.train_files if car_image_id in s]\n",
    "        raise Exception(\"No image with this ID found\")\n",
    "\n",
    "    def get_image_matrix(self, image_path):\n",
    "        img = Image.open(image_path)\n",
    "        return np.asarray(img, dtype=np.uint8)\n",
    "\n",
    "    def get_image_size(self, image):\n",
    "        img = Image.open(image)\n",
    "        return img.size\n",
    "\n",
    "    def get_train_files(self, validation_size=0.2, sample_size=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            validation_size (float):\n",
    "                 Value between 0 and 1\n",
    "            sample_size (float, None):\n",
    "                Value between 0 and 1 or None.\n",
    "                Whether you want to have a sample of your dataset.\n",
    "\n",
    "        Returns:\n",
    "            list :\n",
    "                Returns the dataset in the form:\n",
    "                [train_data, train_masks_data, valid_data, valid_masks_data]\n",
    "        \"\"\"\n",
    "        train_ids = self.train_ids\n",
    "\n",
    "        # Each id has 16 images but well...\n",
    "        if sample_size:\n",
    "            rnd = np.random.choice(self.train_ids, int(len(self.train_ids) * sample_size))\n",
    "            train_ids = rnd.ravel()\n",
    "\n",
    "        if validation_size:\n",
    "            ids_train_split, ids_valid_split = train_test_split(train_ids, test_size=validation_size)\n",
    "        else:\n",
    "            ids_train_split = train_ids\n",
    "            ids_valid_split = []\n",
    "\n",
    "        train_ret = []\n",
    "        train_masks_ret = []\n",
    "        valid_ret = []\n",
    "        valid_masks_ret = []\n",
    "\n",
    "        for id in ids_train_split:\n",
    "            train_ret.append(self.get_car_image_files(id))\n",
    "            train_masks_ret.append(self.get_car_image_files(id, get_mask=True))\n",
    "\n",
    "        for id in ids_valid_split:\n",
    "            valid_ret.append(self.get_car_image_files(id))\n",
    "            valid_masks_ret.append(self.get_car_image_files(id, get_mask=True))\n",
    "\n",
    "        return [np.array(train_ret).ravel(), np.array(train_masks_ret).ravel(),\n",
    "                np.array(valid_ret).ravel(), np.array(valid_masks_ret).ravel()]\n",
    "\n",
    "    def get_test_files(self, sample_size):\n",
    "        test_files = self.test_files\n",
    "\n",
    "        if sample_size:\n",
    "            rnd = np.random.choice(self.test_files, int(len(self.test_files) * sample_size))\n",
    "            test_files = rnd.ravel()\n",
    "\n",
    "        ret = [None] * len(test_files)\n",
    "        for i, file in enumerate(test_files):\n",
    "            ret[i] = self.test_data + \"/\" + file\n",
    "\n",
    "        return np.array(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(optimizer):\n",
    "    lr = []\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr += [param_group['lr']]\n",
    "    return lr\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class TensorboardVisualizerCallback(Callback):\n",
    "    def __init__(self, path_to_files):\n",
    "        \"\"\"\n",
    "            Callback intended to be executed at each epoch\n",
    "            of the training which goal is to display the result\n",
    "            of the last validation batch in Tensorboard\n",
    "        Args:\n",
    "            path_to_files (str): The path where to store the log files\n",
    "        \"\"\"\n",
    "        self.path_to_files = path_to_files\n",
    "\n",
    "    def _apply_mask_overlay(self, image, mask, color=(0, 255, 0)):\n",
    "        mask = np.dstack((mask, mask, mask)) * np.array(color)\n",
    "        mask = mask.astype(np.uint8)\n",
    "        return cv2.addWeighted(mask, 0.5, image, 0.5, 0.)  # image * α + mask * β + λ\n",
    "\n",
    "    def _get_mask_representation(self, image, mask):\n",
    "        \"\"\"\n",
    "         Given a mask and an image this method returns\n",
    "         one image representing 3 patches of the same image.\n",
    "         These patches represent:\n",
    "            - The original image\n",
    "            - The original mask\n",
    "            - The mask applied to the original image\n",
    "        Args:\n",
    "            image (np.ndarray): The original image\n",
    "            mask (np.ndarray): The predicted mask\n",
    "\n",
    "        Returns (np.ndarray):\n",
    "            An image of size (original_image_height, (original_image_width * 3))\n",
    "            showing 3 patches of the original image\n",
    "        \"\"\"\n",
    "\n",
    "        H, W, C = image.shape\n",
    "        mask = cv2.resize(mask, (H, W))\n",
    "        results = np.zeros((H, 3 * W, 3), np.uint8)\n",
    "        p = np.zeros((H * W, 3), np.uint8)\n",
    "\n",
    "        m = np.zeros((H * W), np.uint8)\n",
    "        l = mask.reshape(-1)\n",
    "        masked_img = self._apply_mask_overlay(image, mask)\n",
    "\n",
    "        a = (2 * l + m)\n",
    "        miss = np.where(a == 2)[0]\n",
    "        hit = np.where(a == 3)[0]\n",
    "        fp = np.where(a == 1)[0]\n",
    "        p[miss] = np.array([0, 0, 255])\n",
    "        p[hit] = np.array([64, 64, 64])\n",
    "        p[fp] = np.array([0, 255, 0])\n",
    "        p = p.reshape(H, W, 3)\n",
    "\n",
    "        results[:, 0:W] = image\n",
    "        results[:, W:2 * W] = p\n",
    "        results[:, 2 * W:3 * W] = masked_img\n",
    "        return results\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if kwargs['step_name'] != \"epoch\":\n",
    "            return\n",
    "\n",
    "        epoch_id = kwargs['epoch_id']\n",
    "        last_images, last_targets, last_preds = kwargs['last_val_batch']\n",
    "        writer = SummaryWriter(self.path_to_files)\n",
    "\n",
    "        for i, (image, target_mask, pred_mask) in enumerate(zip(last_images, last_targets, last_preds)):\n",
    "\n",
    "            image = image.data.float().cpu().numpy().astype(np.uint8)\n",
    "            image = np.transpose(image, (1, 2, 0))  # Invert c, h, w to h, w, c\n",
    "            target_mask = target_mask.float().data.cpu().numpy().astype(np.uint8)\n",
    "            pred_mask = pred_mask.float().data.cpu().numpy().astype(np.uint8)\n",
    "            expected_result = self._get_mask_representation(image, target_mask)\n",
    "            pred_result = self._get_mask_representation(image, pred_mask)\n",
    "            writer.add_image(\"Epoch_\" + str(epoch_id) + '-Image_' + str(i + 1) + '-Expected', expected_result, epoch_id)\n",
    "            writer.add_image(\"Epoch_\" + str(epoch_id) + '-Image_' + str(i + 1) + '-Predicted', pred_result, epoch_id)\n",
    "            if i == 1:  # 2 Images are sufficient\n",
    "                break\n",
    "        writer.close()\n",
    "\n",
    "\n",
    "class TensorboardLoggerCallback(Callback):\n",
    "    def __init__(self, path_to_files):\n",
    "        \"\"\"\n",
    "            Callback intended to be executed at each epoch\n",
    "            of the training which goal is to add valuable\n",
    "            information to the tensorboard logs such as the losses\n",
    "            and accuracies\n",
    "        Args:\n",
    "            path_to_files (str): The path where to store the log files\n",
    "        \"\"\"\n",
    "        self.path_to_files = path_to_files\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if kwargs['step_name'] != \"epoch\":\n",
    "            return\n",
    "\n",
    "        epoch_id = kwargs['epoch_id']\n",
    "\n",
    "        writer = SummaryWriter(self.path_to_files)\n",
    "        writer.add_scalar('data/train_loss', kwargs['train_loss'], epoch_id)\n",
    "        writer.add_scalar('data/train_dice_coeff', kwargs['train_dice_coeff'], epoch_id)\n",
    "        writer.add_scalar('data/val_loss', kwargs['val_loss'], epoch_id)\n",
    "        writer.add_scalar('data/val_dice_coeff', kwargs['val_dice_coeff'], epoch_id)\n",
    "        writer.close()\n",
    "\n",
    "\n",
    "class ModelSaverCallback(Callback):\n",
    "    def __init__(self, path_to_model, verbose=False):\n",
    "        \"\"\"\n",
    "            Callback intended to be executed each time a whole train pass\n",
    "            get finished. This callback saves the model in the given path\n",
    "        Args:\n",
    "            verbose (bool): True or False to make the callback verbose\n",
    "            path_to_model (str): The path where to store the model\n",
    "        \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.path_to_model = path_to_model\n",
    "        self.suffix = \"\"\n",
    "\n",
    "    def set_suffix(self, suffix):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            suffix (str): The suffix to append to the model file name\n",
    "        \"\"\"\n",
    "        self.suffix = suffix\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if kwargs['step_name'] != \"train\":\n",
    "            return\n",
    "\n",
    "        pth = self.path_to_model + self.suffix\n",
    "        net = kwargs['net']\n",
    "        torch.save(net.state_dict(), pth)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Model saved in {}\".format(pth))\n",
    "\n",
    "\n",
    "class PredictionsSaverCallback(Callback):\n",
    "    def __init__(self, to_file, origin_img_size, threshold):\n",
    "        self.threshold = threshold\n",
    "        self.origin_img_size = origin_img_size\n",
    "        self.to_file = to_file\n",
    "        self.file = gzip.open(to_file, \"wt\", newline=\"\")\n",
    "        self.writer = csv.writer(self.file)\n",
    "        self.writer.writerow([\"img\", \"rle_mask\"])\n",
    "\n",
    "    # https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "    def run_length_encode(self, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mask (np.ndarray): 1 = mask, 0 = background\n",
    "\n",
    "        Returns:\n",
    "            str: run length as string formated\n",
    "        \"\"\"\n",
    "        inds = mask.flatten()\n",
    "        runs = np.where(inds[1:] != inds[:-1])[0] + 2\n",
    "        runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "        rle = ' '.join([str(r) for r in runs])\n",
    "        return rle\n",
    "\n",
    "    def get_mask_rle(self, prediction):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            prediction (np.ndarray): An array of predicted values\n",
    "\n",
    "        Returns:\n",
    "            str: A length encoded version of the passed prediction\n",
    "        \"\"\"\n",
    "        mask = cv2.resize(prediction, self.origin_img_size)\n",
    "        mask = mask > self.threshold\n",
    "        return self.run_length_encode(mask)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if kwargs['step_name'] != \"predict\":\n",
    "            return\n",
    "\n",
    "        probs = kwargs['probs']\n",
    "        files_name = kwargs['files_name']\n",
    "        # Save the predictions\n",
    "        for (pred, name) in zip(probs, files_name):\n",
    "            rle = self.get_mask_rle(pred)\n",
    "            self.writer.writerow([name, rle])\n",
    "\n",
    "    def close_saver(self):\n",
    "        self.file.flush()\n",
    "        self.file.close()\n",
    "        print(\"Predictions wrote in {} file\".format(self.to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_shift_scale_rotate(image, angle, scale, aspect, shift_dx, shift_dy,\n",
    "                              borderMode=cv2.BORDER_CONSTANT, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        if len(image.shape) == 3:  # Img or mask\n",
    "            height, width, channels = image.shape\n",
    "        else:\n",
    "            height, width = image.shape\n",
    "\n",
    "        sx = scale * aspect / (aspect ** 0.5)\n",
    "        sy = scale / (aspect ** 0.5)\n",
    "        dx = round(shift_dx * width)\n",
    "        dy = round(shift_dy * height)\n",
    "\n",
    "        cc = np.math.cos(angle / 180 * np.math.pi) * sx\n",
    "        ss = np.math.sin(angle / 180 * np.math.pi) * sy\n",
    "        rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    "\n",
    "        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])\n",
    "        box1 = box0 - np.array([width / 2, height / 2])\n",
    "        box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])\n",
    "\n",
    "        box0 = box0.astype(np.float32)\n",
    "        box1 = box1.astype(np.float32)\n",
    "        mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "\n",
    "        image = cv2.warpPerspective(image, mat, (width, height), flags=cv2.INTER_LINEAR,\n",
    "                                    borderMode=borderMode, borderValue=(0, 0, 0, 0))\n",
    "    return image\n",
    "\n",
    "\n",
    "def random_horizontal_flip(image, mask, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.flip(image, 1)\n",
    "        mask = cv2.flip(mask, 1)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def augment_img(img, mask):\n",
    "    rotate_limit = (-45, 45)\n",
    "    aspect_limit = (0, 0)\n",
    "    scale_limit = (-0.1, 0.1)\n",
    "    shift_limit = (-0.0625, 0.0625)\n",
    "    shift_dx = np.random.uniform(shift_limit[0], shift_limit[1])\n",
    "    shift_dy = np.random.uniform(shift_limit[0], shift_limit[1])\n",
    "    angle = np.random.uniform(rotate_limit[0], rotate_limit[1])  # degree\n",
    "    scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n",
    "    aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n",
    "\n",
    "    img = random_shift_scale_rotate(img, angle, scale, aspect, shift_dx, shift_dy)\n",
    "    mask = random_shift_scale_rotate(mask, angle, scale, aspect, shift_dx, shift_dy)\n",
    "\n",
    "    img, mask = random_horizontal_flip(img, mask)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropyLoss2d(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        \"\"\"\n",
    "        Binary cross entropy loss 2D\n",
    "        Args:\n",
    "            weight:\n",
    "            size_average:\n",
    "        \"\"\"\n",
    "        super(BinaryCrossEntropyLoss2d, self).__init__()\n",
    "        self.bce_loss = nn.BCELoss(weight, size_average)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.sigmoid(logits)\n",
    "        probs_flat = probs.view(-1)  # Flatten\n",
    "        targets_flat = targets.view(-1)  # Flatten\n",
    "        return self.bce_loss(probs_flat, targets_flat)\n",
    "\n",
    "\n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        smooth = 1\n",
    "        num = targets.size(0)\n",
    "        probs = F.sigmoid(logits)\n",
    "        m1 = probs.view(num, -1)\n",
    "        m2 = targets.view(num, -1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score\n",
    "\n",
    "\n",
    "# https://github.com/pytorch/pytorch/issues/1249\n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    num = pred.size(0)\n",
    "    m1 = pred.view(num, -1)  # Flatten\n",
    "    m2 = target.view(num, -1)  # Flatten\n",
    "    intersection = (m1 * m2).sum()\n",
    "\n",
    "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarvanaClassifier:\n",
    "    def __init__(self, net, max_epochs):\n",
    "        \"\"\"\n",
    "        The classifier for carvana used for training and launching predictions\n",
    "        Args:\n",
    "            net (nn.Module): The neural net module containing the definition of your model\n",
    "            max_epochs (int): The maximum number of epochs on which the model will train\n",
    "        \"\"\"\n",
    "        self.net = net\n",
    "        self.max_epochs = max_epochs\n",
    "        self.epoch_counter = 0\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    def restore_model(self, model_path):\n",
    "        \"\"\"\n",
    "            Restore a model parameters from the one given in argument\n",
    "        Args:\n",
    "            model_path (str): The path to the model to restore\n",
    "\n",
    "        \"\"\"\n",
    "        self.net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    def _criterion(self, logits, labels):\n",
    "        return losses_utils.BinaryCrossEntropyLoss2d().forward(logits, labels) + \\\n",
    "            losses_utils.SoftDiceLoss().forward(logits, labels)\n",
    "\n",
    "    def _validate_epoch(self, valid_loader, threshold):\n",
    "        losses = tools.AverageMeter()\n",
    "        dice_coeffs = tools.AverageMeter()\n",
    "\n",
    "        it_count = len(valid_loader)\n",
    "        batch_size = valid_loader.batch_size\n",
    "\n",
    "        images = None  # To save the last images batch\n",
    "        targets = None  # To save the last target batch\n",
    "        preds = None  # To save the last prediction batch\n",
    "        with tqdm(total=it_count, desc=\"Validating\", leave=False) as pbar:\n",
    "            for ind, (images, targets) in enumerate(valid_loader):\n",
    "                if self.use_cuda:\n",
    "                    images = images.cuda()\n",
    "                    targets = targets.cuda()\n",
    "\n",
    "                # Volatile because we are in pure inference mode\n",
    "                # http://pytorch.org/docs/master/notes/autograd.html#volatile\n",
    "                images = Variable(images, volatile=True)\n",
    "                targets = Variable(targets, volatile=True)\n",
    "\n",
    "                # forward\n",
    "                logits = self.net(images)\n",
    "                probs = F.sigmoid(logits)\n",
    "                preds = (probs > threshold).float()\n",
    "\n",
    "                loss = self._criterion(logits, targets)\n",
    "                acc = losses_utils.dice_coeff(preds, targets)\n",
    "                losses.update(loss.data[0], batch_size)\n",
    "                dice_coeffs.update(acc.data[0], batch_size)\n",
    "                pbar.update(1)\n",
    "\n",
    "        return losses.avg, dice_coeffs.avg, images, targets, preds\n",
    "\n",
    "    def _train_epoch(self, train_loader, optimizer, threshold):\n",
    "        losses = tools.AverageMeter()\n",
    "        dice_coeffs = tools.AverageMeter()\n",
    "\n",
    "        # Total training files count / batch_size\n",
    "        batch_size = train_loader.batch_size\n",
    "        it_count = len(train_loader)\n",
    "        with tqdm(total=it_count,\n",
    "                  desc=\"Epochs {}/{}\".format(self.epoch_counter + 1, self.max_epochs),\n",
    "                  bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{remaining}{postfix}]'\n",
    "                  ) as pbar:\n",
    "            for ind, (inputs, target) in enumerate(train_loader):\n",
    "\n",
    "                if self.use_cuda:\n",
    "                    inputs = inputs.cuda()\n",
    "                    target = target.cuda()\n",
    "                inputs, target = Variable(inputs), Variable(target)\n",
    "\n",
    "                # forward\n",
    "                logits = self.net.forward(inputs)\n",
    "                probs = F.sigmoid(logits)\n",
    "                pred = (probs > threshold).float()\n",
    "\n",
    "                # backward + optimize\n",
    "                loss = self._criterion(logits, target)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                acc = losses_utils.dice_coeff(pred, target)\n",
    "\n",
    "                losses.update(loss.data[0], batch_size)\n",
    "                dice_coeffs.update(acc.data[0], batch_size)\n",
    "\n",
    "                # Update pbar\n",
    "                pbar.set_postfix(OrderedDict(loss='{0:1.5f}'.format(loss.data[0]),\n",
    "                                             dice_coeff='{0:1.5f}'.format(acc.data[0])))\n",
    "                pbar.update(1)\n",
    "        return losses.avg, dice_coeffs.avg\n",
    "\n",
    "    @st_time(show_func_name=False)\n",
    "    def _run_epoch(self, train_loader: DataLoader, valid_loader: DataLoader,\n",
    "                   optimizer, threshold=0.5, callbacks=None):\n",
    "        # switch to train mode\n",
    "        self.net.train()\n",
    "\n",
    "        # Run a train pass on the current epoch\n",
    "        train_loss, train_dice_coeff = self._train_epoch(train_loader, optimizer, threshold)\n",
    "\n",
    "        # switch to evaluate mode\n",
    "        self.net.eval()\n",
    "\n",
    "        # Run the validation pass\n",
    "        val_loss, val_dice_coeff, last_images, last_targets, last_preds = \\\n",
    "            self._validate_epoch(valid_loader, threshold)\n",
    "\n",
    "        # If there are callback call their __call__ method and pass in some arguments\n",
    "        if callbacks:\n",
    "            for cb in callbacks:\n",
    "                cb(step_name=\"epoch\",\n",
    "                   net=self.net,\n",
    "                   last_val_batch=(last_images, last_targets, last_preds),\n",
    "                   epoch_id=self.epoch_counter + 1,\n",
    "                   train_loss=train_loss, train_dice_coeff=train_dice_coeff,\n",
    "                   val_loss=val_loss, val_dice_coeff=val_dice_coeff\n",
    "                   )\n",
    "        print(\"train_loss = {:03f}, train_dice_coeff = {:03f}\\n\"\n",
    "              \"val_loss   = {:03f}, val_dice_coeff   = {:03f}\"\n",
    "              .format(train_loss, train_dice_coeff, val_loss, val_dice_coeff))\n",
    "        self.epoch_counter += 1\n",
    "\n",
    "    def train(self, train_loader: DataLoader, valid_loader: DataLoader,\n",
    "              optimizer, epochs, threshold=0.5, callbacks=None):\n",
    "        \"\"\"\n",
    "            Trains the neural net\n",
    "        Args:\n",
    "            train_loader (DataLoader): The Dataloader for training\n",
    "            valid_loader (DataLoader): The Dataloader for validation\n",
    "            optimizer (Optimizer): The nn optimizer\n",
    "            epochs (int): number of epochs\n",
    "            threshold (float): The threshold used to consider the mask present or not\n",
    "            callbacks (list): List of callbacks functions to call at each epoch\n",
    "        Returns:\n",
    "            str, None: The path where the model was saved, or None if it wasn't saved\n",
    "        \"\"\"\n",
    "        if self.use_cuda:\n",
    "            self.net.cuda()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self._run_epoch(train_loader, valid_loader, optimizer, threshold, callbacks)\n",
    "\n",
    "        # If there are callback call their __call__ method and pass in some arguments\n",
    "        if callbacks:\n",
    "            for cb in callbacks:\n",
    "                cb(step_name=\"train\",\n",
    "                   net=self.net,\n",
    "                   epoch_id=self.epoch_counter + 1,\n",
    "                   )\n",
    "\n",
    "    def predict(self, test_loader, callbacks=None):\n",
    "        \"\"\"\n",
    "            Launch the prediction on the given loader and pass\n",
    "            each predictions to the given callbacks.\n",
    "        Args:\n",
    "            test_loader (DataLoader): The loader containing the test dataset\n",
    "            callbacks (list): List of callbacks functions to call at prediction pass\n",
    "        \"\"\"\n",
    "        # Switch to evaluation mode\n",
    "        self.net.eval()\n",
    "\n",
    "        it_count = len(test_loader)\n",
    "\n",
    "        with tqdm(total=it_count, desc=\"Classifying\") as pbar:\n",
    "            for ind, (images, files_name) in enumerate(test_loader):\n",
    "                if self.use_cuda:\n",
    "                    images = images.cuda()\n",
    "\n",
    "                images = Variable(images, volatile=True)\n",
    "\n",
    "                # forward\n",
    "                logits = self.net(images)\n",
    "                probs = F.sigmoid(logits)\n",
    "                probs = probs.data.cpu().numpy()\n",
    "\n",
    "                # If there are callback call their __call__ method and pass in some arguments\n",
    "                if callbacks:\n",
    "                    for cb in callbacks:\n",
    "                        cb(step_name=\"predict\",\n",
    "                           net=self.net,\n",
    "                           probs=probs,\n",
    "                           files_name=files_name\n",
    "                           )\n",
    "\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN_EPS = 1e-4\n",
    "\n",
    "\n",
    "class ConvBnRelu2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3, 3), padding=1):\n",
    "        super(ConvBnRelu2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=BN_EPS)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StackEncoder1024(nn.Module):\n",
    "    def __init__(self, x_channels, y_channels, kernel_size=(3, 3)):\n",
    "        super(StackEncoder, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.encode = nn.Sequential(\n",
    "            ConvBnRelu2d(x_channels, y_channels, kernel_size=kernel_size, padding=padding),\n",
    "            ConvBnRelu2d(y_channels, y_channels, kernel_size=kernel_size, padding=padding),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        x_small = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        return x, x_small\n",
    "\n",
    "\n",
    "class StackDecoder1024(nn.Module):\n",
    "    def __init__(self, x_big_channels, x_channels, y_channels, kernel_size=3):\n",
    "        super(StackDecoder, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "\n",
    "        self.decode = nn.Sequential(\n",
    "            ConvBnRelu2d(x_big_channels + x_channels, y_channels, kernel_size=kernel_size, padding=padding),\n",
    "            ConvBnRelu2d(y_channels, y_channels, kernel_size=kernel_size, padding=padding),\n",
    "            ConvBnRelu2d(y_channels, y_channels, kernel_size=kernel_size, padding=padding),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, down_tensor):\n",
    "        _, channels, height, width = down_tensor.size()\n",
    "        x = F.upsample(x, size=(height, width), mode='bilinear')\n",
    "        x = torch.cat([x, down_tensor], 1)\n",
    "        x = self.decode(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 1024x1024\n",
    "class UNet1024(nn.Module):\n",
    "    def __init__(self, in_shape):\n",
    "        super(UNet1024, self).__init__()\n",
    "        channels, height, width = in_shape\n",
    "\n",
    "        # 1024\n",
    "        self.down1 = StackEncoder1024(channels, 24, kernel_size=3)  # 512\n",
    "        self.down2 = StackEncoder1024(24, 64, kernel_size=3)  # 256\n",
    "        self.down3 = StackEncoder1024(64, 128, kernel_size=3)  # 128\n",
    "        self.down4 = StackEncoder1024(128, 256, kernel_size=3)  # 64\n",
    "        self.down5 = StackEncoder1024(256, 512, kernel_size=3)  # 32\n",
    "        self.down6 = StackEncoder1024(512, 768, kernel_size=3)  # 16\n",
    "\n",
    "        self.center = nn.Sequential(\n",
    "            ConvBnRelu2d(768, 768, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        # 8\n",
    "        # x_big_channels, x_channels, y_channels\n",
    "        self.up6 = StackDecoder1024(768, 768, 512, kernel_size=3)  # 16\n",
    "        self.up5 = StackDecoder1024(512, 512, 256, kernel_size=3)  # 32\n",
    "        self.up4 = StackDecoder1024(256, 256, 128, kernel_size=3)  # 64\n",
    "        self.up3 = StackDecoder1024(128, 128, 64, kernel_size=3)  # 128\n",
    "        self.up2 = StackDecoder1024(64, 64, 24, kernel_size=3)  # 256\n",
    "        self.up1 = StackDecoder1024(24, 24, 24, kernel_size=3)  # 512\n",
    "        self.classify = nn.Conv2d(24, 1, kernel_size=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        down1, out = self.down1(out)\n",
    "        down2, out = self.down2(out)\n",
    "        down3, out = self.down3(out)\n",
    "        down4, out = self.down4(out)\n",
    "        down5, out = self.down5(out)\n",
    "        down6, out = self.down6(out)\n",
    "\n",
    "        out = self.center(out)\n",
    "        out = self.up6(out, down6)\n",
    "        out = self.up5(out, down5)\n",
    "        out = self.up4(out, down4)\n",
    "        out = self.up3(out, down3)\n",
    "        out = self.up2(out, down2)\n",
    "        out = self.up1(out, down1)\n",
    "\n",
    "        out = self.classify(out)\n",
    "        out = torch.squeeze(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):\n",
    "        super(ConvBnRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StackEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(StackEncoder, self).__init__()\n",
    "        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)\n",
    "        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convr1(x)\n",
    "        x = self.convr2(x)\n",
    "        x_trace = x\n",
    "        x = self.maxPool(x)\n",
    "        return x, x_trace\n",
    "\n",
    "\n",
    "class StackDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, upsample_size):\n",
    "        super(StackDecoder, self).__init__()\n",
    "\n",
    "        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode=\"bilinear\")\n",
    "        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)\n",
    "        # Crop + concat step between these 2\n",
    "        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)\n",
    "\n",
    "    def _crop_concat(self, upsampled, bypass):\n",
    "        \"\"\"\n",
    "         Crop y to the (h, w) of x and concat them.\n",
    "         Used for the expansive path.\n",
    "        Returns:\n",
    "            The concatenated tensor\n",
    "        \"\"\"\n",
    "        c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "        bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
    "\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "\n",
    "    def forward(self, x, down_tensor):\n",
    "        x = self.upSample(x)\n",
    "        x = self.convr1(x)\n",
    "        x = self._crop_concat(x, down_tensor)\n",
    "        x = self.convr2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetOriginal(nn.Module):\n",
    "    def __init__(self, in_shape):\n",
    "        super(UNetOriginal, self).__init__()\n",
    "        channels, height, width = in_shape\n",
    "\n",
    "        self.down1 = StackEncoder(channels, 64)\n",
    "        self.down2 = StackEncoder(64, 128)\n",
    "        self.down3 = StackEncoder(128, 256)\n",
    "        self.down4 = StackEncoder(256, 512)\n",
    "\n",
    "        self.center = nn.Sequential(\n",
    "            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),\n",
    "            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(56, 56))\n",
    "        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(104, 104))\n",
    "        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(200, 200))\n",
    "        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(392, 392))\n",
    "\n",
    "        # 1x1 convolution at the last layer\n",
    "        # Different from the paper is the output size here\n",
    "        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, x_trace1 = self.down1(x)  # Calls the forward() method of each layer\n",
    "        x, x_trace2 = self.down2(x)\n",
    "        x, x_trace3 = self.down3(x)\n",
    "        x, x_trace4 = self.down4(x)\n",
    "\n",
    "        x = self.center(x)\n",
    "\n",
    "        x = self.up1(x, x_trace4)\n",
    "        x = self.up2(x, x_trace3)\n",
    "        x = self.up3(x, x_trace2)\n",
    "        x = self.up4(x, x_trace1)\n",
    "\n",
    "        out = self.output_seg_map(x)\n",
    "        out = torch.squeeze(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_img_resize = (572, 572)  # The resize size of the input images of the neural net\n",
    "output_img_resize = (388, 388)  # The resize size of the output images of the neural net\n",
    "# input_img_resize = (1024, 1024)\n",
    "# output_img_resize = (1024, 1024)\n",
    "batch_size = 3\n",
    "epochs = 1\n",
    "threshold = 0.5\n",
    "validation_size = 0.2\n",
    "sample_size = None  # Put 'None' to work on full dataset or a value between 0 and 1\n",
    "# -- Optional parameters\n",
    "threads = cpu_count()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "script_dir = '..'\n",
    "# Training callbacks\n",
    "tb_viz_cb = TensorboardVisualizerCallback(os.path.join(script_dir, '/logs/tb_viz'))\n",
    "tb_logs_cb = TensorboardLoggerCallback(os.path.join(script_dir, '/logs/tb_logs'))\n",
    "model_saver_cb = ModelSaverCallback(os.path.join(script_dir, '/output/models/model_' + get_model_timestamp()), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the datasets\n",
    "ds_fetcher = DatasetFetcher()\n",
    "ds_fetcher.download_dataset()\n",
    "\n",
    "# Get the path to the files for the neural net\n",
    "X_train, y_train, X_valid, y_valid = ds_fetcher.get_train_files(sample_size=sample_size,\n",
    "                                                                validation_size=validation_size)\n",
    "full_x_test = ds_fetcher.get_test_files(sample_size)\n",
    "\n",
    "# -- Computed parameters\n",
    "# Get the original images size (assuming they are all the same size)\n",
    "origin_img_size = ds_fetcher.get_image_size(X_train[0])\n",
    "\n",
    "# Testing callbacks\n",
    "pred_saver_cb = PredictionsSaverCallback(os.path.join(script_dir, '/output/submit.csv.gz'),\n",
    "                                         origin_img_size, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define our neural net architecture\n",
    "# The original paper has 1 input channel,\n",
    "# in our case we have 3 (RGB)\n",
    "#net = UNet1024((3, *input_img_resize))\n",
    "net = UNetOriginal((3, *input_img_resize))\n",
    "classifier = CarvanaClassifier(net, epochs)\n",
    "# optimizer = optim.RMSprop(net.parameters(), lr=0.0002)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.99)\n",
    "\n",
    "train_ds = TrainImageDataset(X_train, y_train, input_img_resize, output_img_resize,\n",
    "                             X_transform=aug.augment_img)\n",
    "train_loader = DataLoader(train_ds, batch_size,\n",
    "                          sampler=RandomSampler(train_ds),\n",
    "                          num_workers=threads,\n",
    "                          pin_memory=use_cuda)\n",
    "\n",
    "valid_ds = TrainImageDataset(X_valid, y_valid, input_img_resize, output_img_resize,\n",
    "                             threshold=threshold)\n",
    "valid_loader = DataLoader(valid_ds, batch_size,\n",
    "                          sampler=SequentialSampler(valid_ds),\n",
    "                          num_workers=threads,\n",
    "                          pin_memory=use_cuda)\n",
    "\n",
    "print(\"Training on {} samples and validating on {} samples \"\n",
    "      .format(len(train_loader.dataset), len(valid_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "classifier.train(train_loader, valid_loader, optimizer,\n",
    "                 epochs, callbacks=[tb_viz_cb, tb_logs_cb, model_saver_cb])\n",
    "\n",
    "test_ds = TestImageDataset(full_x_test, input_img_resize)\n",
    "test_loader = DataLoader(test_ds, batch_size,\n",
    "                         sampler=SequentialSampler(test_ds),\n",
    "                         num_workers=threads,\n",
    "                         pin_memory=use_cuda)\n",
    "\n",
    "# Predict & save\n",
    "classifier.predict(test_loader, callbacks=[pred_saver_cb])\n",
    "pred_saver_cb.close_saver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
